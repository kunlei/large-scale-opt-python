[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hands-on Large Scale Optimization in Python",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "preface.html#install-homebrew",
    "href": "preface.html#install-homebrew",
    "title": "1  Environment Setup",
    "section": "1.1 Install Homebrew",
    "text": "1.1 Install Homebrew\nThe first tool we need is Homebrew, ‘the Missing Package Manager for macOS (or Linux)’, and it can be accessed at https://brew.sh/. To install Homebrew, just copy the command below and run it in the Terminal.\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nWe can then use the brew --version command to check the installed version. On my system, it shows the info below.\n ~/ brew --version\nHomebrew 3.6.20\nHomebrew/homebrew-core (git revision 5f1582e4d55; last commit 2023-02-05)\nHomebrew/homebrew-cask (git revision fa3b8a669d; last commit 2023-02-05)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "preface.html#install-anaconda",
    "href": "preface.html#install-anaconda",
    "title": "1  Environment Setup",
    "section": "1.2 Install Anaconda",
    "text": "1.2 Install Anaconda\nSince there are several Python versions available for our use and we may end up having multiple Python versions installed on our machine, it is important to use a consistent environment to work on our project in. Anaconda is a package and environment manager for Python and it provides easy-to-use tools to facilitate our data science needs. To install Anaconda, run the below command in the Terminal.\n ~/ brew install anaconda\nAfter the installation is done, we can use conda --version to verify whether it is available on our machine or not.\n ~/ conda --version\nconda 23.1.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "preface.html#create-a-conda-environment",
    "href": "preface.html#create-a-conda-environment",
    "title": "1  Environment Setup",
    "section": "1.3 Create a Conda Environment",
    "text": "1.3 Create a Conda Environment\nNow we will create a Conda environment named ‘ortools’. Execute the below command in the Terminal, which effectively creates the required environment with Python version 3.10.\n ~/ conda create -n ortools python=3.10\nRetrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/homebrew/anaconda3/envs/test\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    setuptools-67.4.0          |     pyhd8ed1ab_0         567 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         567 KB\n\nThe following NEW packages will be INSTALLED:\n\n  bzip2              conda-forge/osx-arm64::bzip2-1.0.8-h3422bc3_4\n  ca-certificates    conda-forge/osx-arm64::ca-certificates-2022.12.7-h4653dfc_0\n  libffi             conda-forge/osx-arm64::libffi-3.4.2-h3422bc3_5\n  libsqlite          conda-forge/osx-arm64::libsqlite-3.40.0-h76d750c_0\n  libzlib            conda-forge/osx-arm64::libzlib-1.2.13-h03a7124_4\n  ncurses            conda-forge/osx-arm64::ncurses-6.3-h07bb92c_1\n  openssl            conda-forge/osx-arm64::openssl-3.0.8-h03a7124_0\n  pip                conda-forge/noarch::pip-23.0.1-pyhd8ed1ab_0\n  python             conda-forge/osx-arm64::python-3.10.9-h3ba56d0_0_cpython\n  readline           conda-forge/osx-arm64::readline-8.1.2-h46ed386_0\n  setuptools         conda-forge/noarch::setuptools-67.4.0-pyhd8ed1ab_0\n  tk                 conda-forge/osx-arm64::tk-8.6.12-he1e0b03_0\n  tzdata             conda-forge/noarch::tzdata-2022g-h191b570_0\n  wheel              conda-forge/noarch::wheel-0.38.4-pyhd8ed1ab_0\n  xz                 conda-forge/osx-arm64::xz-5.2.6-h57fd34a_0\n\n\nProceed ([y]/n)?\nType ‘y’ to proceed and Conda will create the environment for us. We can use cnoda env list to show all the created environments on our machine:\n ~/ conda env list\n# conda environments:\n#\nbase                     /opt/homebrew/anaconda3\nortools                   /opt/homebrew/anaconda3/envs/ortools\nNote that we need to manually activate an environemnt in order to use it: conda activate ortools. On my machine, the activated environment ortools will appear in the beginning of my prompt.\n ~/ conda activate ortools\n(ortools)  ~/",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "preface.html#install-google-or-tools",
    "href": "preface.html#install-google-or-tools",
    "title": "1  Environment Setup",
    "section": "1.4 Install Google OR-Tools",
    "text": "1.4 Install Google OR-Tools\nAs of this writing, the latest version of Google OR-Tools is 9.5.2237, and we can install it in our newly created environment using the command pip install ortools==9.5.2237. We can use conda list to verify whether it is available in our environment.\n(ortools)  ~/ conda list\n# packages in environment at /opt/homebrew/anaconda3/envs/ortools:\n#\n# Name                    Version                   Build  Channel\nabsl-py                   1.4.0                    pypi_0    pypi\nbzip2                     1.0.8                h3422bc3_4    conda-forge\nca-certificates           2022.12.7            h4653dfc_0    conda-forge\nlibffi                    3.4.2                h3422bc3_5    conda-forge\nlibsqlite                 3.40.0               h76d750c_0    conda-forge\nlibzlib                   1.2.13               h03a7124_4    conda-forge\nncurses                   6.3                  h07bb92c_1    conda-forge\nnumpy                     1.24.2                   pypi_0    pypi\nopenssl                   3.0.8                h03a7124_0    conda-forge\nortools                   9.5.2237                 pypi_0    pypi\npip                       23.0.1             pyhd8ed1ab_0    conda-forge\nprotobuf                  4.22.0                   pypi_0    pypi\npython                    3.10.9          h3ba56d0_0_cpython    conda-forge\nreadline                  8.1.2                h46ed386_0    conda-forge\nsetuptools                67.4.0             pyhd8ed1ab_0    conda-forge\ntk                        8.6.12               he1e0b03_0    conda-forge\ntzdata                    2022g                h191b570_0    conda-forge\nwheel                     0.38.4             pyhd8ed1ab_0    conda-forge\nxz                        5.2.6                h57fd34a_0    conda-forge\nNow we have Python and Google OR-Tools ready, we can start our next journey.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "env-setup.html#install-homebrew",
    "href": "env-setup.html#install-homebrew",
    "title": "3  Environment Setup",
    "section": "3.1 Install Homebrew",
    "text": "3.1 Install Homebrew\nThe first tool we need is Homebrew, ‘the Missing Package Manager for macOS (or Linux)’, and it can be accessed at https://brew.sh/. To install Homebrew, just copy the command below and run it in the Terminal.\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nWe can then use the brew --version command to check the installed version. On my system, it shows the info below.\n ~/ brew --version\nHomebrew 3.6.20\nHomebrew/homebrew-core (git revision 5f1582e4d55; last commit 2023-02-05)\nHomebrew/homebrew-cask (git revision fa3b8a669d; last commit 2023-02-05)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env-setup.html#install-anaconda",
    "href": "env-setup.html#install-anaconda",
    "title": "3  Environment Setup",
    "section": "3.2 Install Anaconda",
    "text": "3.2 Install Anaconda\nSince there are several Python versions available for our use and we may end up having multiple Python versions installed on our machine, it is important to use a consistent environment to work on our project in. Anaconda is a package and environment manager for Python and it provides easy-to-use tools to facilitate our data science needs. To install Anaconda, run the below command in the Terminal.\n ~/ brew install anaconda\nAfter the installation is done, we can use conda --version to verify whether it is available on our machine or not.\n ~/ conda --version\nconda 23.1.0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env-setup.html#create-a-conda-environment",
    "href": "env-setup.html#create-a-conda-environment",
    "title": "3  Environment Setup",
    "section": "3.3 Create a Conda Environment",
    "text": "3.3 Create a Conda Environment\nNow we will create a Conda environment named ‘ortools’. Execute the below command in the Terminal, which effectively creates the required environment with Python version 3.10.\n ~/ conda create -n ortools python=3.10\nRetrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/homebrew/anaconda3/envs/test\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    setuptools-67.4.0          |     pyhd8ed1ab_0         567 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         567 KB\n\nThe following NEW packages will be INSTALLED:\n\n  bzip2              conda-forge/osx-arm64::bzip2-1.0.8-h3422bc3_4\n  ca-certificates    conda-forge/osx-arm64::ca-certificates-2022.12.7-h4653dfc_0\n  libffi             conda-forge/osx-arm64::libffi-3.4.2-h3422bc3_5\n  libsqlite          conda-forge/osx-arm64::libsqlite-3.40.0-h76d750c_0\n  libzlib            conda-forge/osx-arm64::libzlib-1.2.13-h03a7124_4\n  ncurses            conda-forge/osx-arm64::ncurses-6.3-h07bb92c_1\n  openssl            conda-forge/osx-arm64::openssl-3.0.8-h03a7124_0\n  pip                conda-forge/noarch::pip-23.0.1-pyhd8ed1ab_0\n  python             conda-forge/osx-arm64::python-3.10.9-h3ba56d0_0_cpython\n  readline           conda-forge/osx-arm64::readline-8.1.2-h46ed386_0\n  setuptools         conda-forge/noarch::setuptools-67.4.0-pyhd8ed1ab_0\n  tk                 conda-forge/osx-arm64::tk-8.6.12-he1e0b03_0\n  tzdata             conda-forge/noarch::tzdata-2022g-h191b570_0\n  wheel              conda-forge/noarch::wheel-0.38.4-pyhd8ed1ab_0\n  xz                 conda-forge/osx-arm64::xz-5.2.6-h57fd34a_0\n\n\nProceed ([y]/n)?\nType ‘y’ to proceed and Conda will create the environment for us. We can use cnoda env list to show all the created environments on our machine:\n ~/ conda env list\n# conda environments:\n#\nbase                     /opt/homebrew/anaconda3\nortools                   /opt/homebrew/anaconda3/envs/ortools\nNote that we need to manually activate an environemnt in order to use it: conda activate ortools. On my machine, the activated environment ortools will appear in the beginning of my prompt.\n ~/ conda activate ortools\n(ortools)  ~/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env-setup.html#install-google-or-tools",
    "href": "env-setup.html#install-google-or-tools",
    "title": "3  Environment Setup",
    "section": "3.4 Install Google OR-Tools",
    "text": "3.4 Install Google OR-Tools\nAs of this writing, the latest version of Google OR-Tools is 9.5.2237, and we can install it in our newly created environment using the command pip install ortools==9.5.2237. We can use conda list to verify whether it is available in our environment.\n(ortools)  ~/ conda list\n# packages in environment at /opt/homebrew/anaconda3/envs/ortools:\n#\n# Name                    Version                   Build  Channel\nabsl-py                   1.4.0                    pypi_0    pypi\nbzip2                     1.0.8                h3422bc3_4    conda-forge\nca-certificates           2022.12.7            h4653dfc_0    conda-forge\nlibffi                    3.4.2                h3422bc3_5    conda-forge\nlibsqlite                 3.40.0               h76d750c_0    conda-forge\nlibzlib                   1.2.13               h03a7124_4    conda-forge\nncurses                   6.3                  h07bb92c_1    conda-forge\nnumpy                     1.24.2                   pypi_0    pypi\nopenssl                   3.0.8                h03a7124_0    conda-forge\nortools                   9.5.2237                 pypi_0    pypi\npip                       23.0.1             pyhd8ed1ab_0    conda-forge\nprotobuf                  4.22.0                   pypi_0    pypi\npython                    3.10.9          h3ba56d0_0_cpython    conda-forge\nreadline                  8.1.2                h46ed386_0    conda-forge\nsetuptools                67.4.0             pyhd8ed1ab_0    conda-forge\ntk                        8.6.12               he1e0b03_0    conda-forge\ntzdata                    2022g                h191b570_0    conda-forge\nwheel                     0.38.4             pyhd8ed1ab_0    conda-forge\nxz                        5.2.6                h57fd34a_0    conda-forge\nNow we have Python and Google OR-Tools ready, we can start our next journey.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "benders-theory.html#the-decomposition-logic",
    "href": "benders-theory.html#the-decomposition-logic",
    "title": "4  Benders Decomposition",
    "section": "4.1 The Decomposition Logic",
    "text": "4.1 The Decomposition Logic\nTo explain the workings of Benders decomposition, let us look at the standard form of linear programming problems that involve two vector variables, \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\). Let \\(p\\) and \\(q\\) indicate the dimensions of \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), respectively. Below is the original problem (P) we intend to solve.\n\\[\\begin{align}\n\\text{min.} &\\quad \\mathbf{c}^T \\mathbf{x} + \\mathbf{f}^T \\mathbf{y} \\\\\n\\text{s.t.} &\\quad \\mathbf{A} \\mathbf{x} + \\mathbf{B} \\mathbf{y} = \\mathbf{b} \\\\\n&\\quad \\mathbf{x} \\geq 0, \\mathbf{y} \\geq 0\n\\end{align}\\]\nIn this formulation, \\(\\mathbf{c}\\) and \\(\\mathbf{f}\\) in the objective function represent the cost coefficients associated with decision variables \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\), respectively. Both of them are column vectors of corresponding dimensions. In the constraints, matrix \\(\\mathbf{A}\\) is of dimension \\(m \\times p\\), and matrix \\(\\mathbf{B}\\) is of dimension \\(m \\times q\\). \\(\\mathbf{b}\\) is a column vector of dimension \\(m\\).\nSuppose the variable \\(\\mathbf{y}\\) is a complicating variable in the sense that the resulting problem is substantially easier to solve if the value of \\(\\mathbf{y}\\) is fixed. In this case, we could rewrite problem \\(\\mathbf{P}\\) as the following form:\n\\[\\begin{align}\n\\text{min.} &\\quad \\mathbf{f}^T \\mathbf{y} + g(\\mathbf{y}) \\\\\n\\text{s.t.} &\\quad \\mathbf{y} \\geq 0\n\\end{align}\\]\nwhere \\(g(\\mathbf{y})\\) is a function of \\(\\mathbf{y}\\) and is defined as the subproblem \\(\\mathbf{SP}\\) of the form below:\n\\[\\begin{align}\n    \\text{min.} &\\quad \\mathbf{c}^T \\mathbf{x} \\\\\n    \\text{s.t.} &\\quad \\mathbf{A} \\mathbf{x}  = \\mathbf{b} - \\mathbf{B} \\mathbf{y} \\label{bd-cons1} \\\\\n    &\\quad \\mathbf{x} \\geq 0\n\\end{align}\\]\nNote that the \\(\\mathbf{y}\\) in constraint \\(\\eqref{bd-cons1}\\) takes on some known values when the problem is solved and the only decision variable in the above formulation is \\(\\mathbf{x}\\). The dual problem of \\(\\mathbf{SP}\\), \\(\\mathbf{DSP}\\), is given below.\n\\[\\begin{align}\n    \\text{max.} &\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u} \\\\\n    \\text{s.t.} &\\quad \\mathbf{A}^T \\mathbf{u} \\leq \\mathbf{c} \\label{bd-cons2} \\\\\n    &\\quad \\mathbf{u}\\  \\text{unrestricted}\n\\end{align}\\]\nA key characteristic of the above \\(\\mathbf{DSP}\\) is that its solution space does not depend on the value of \\(\\mathbf{y}\\), which only affects the objective function. According to the Minkowski’s representation theorem, any \\(\\bar{\\mathbf{u}}\\) satisfying the constraints \\(\\eqref{bd-cons2}\\) can be expressed as\n\\[\\begin{align}\n\\bar{\\mathbf{u}} = \\sum_{j \\in \\mathbf{J}} \\lambda_j \\mathbf{u}_{j}^{point} + \\sum_{k \\in \\mathbf{K}} \\mu_k \\mathbf{u}_k^{ray}\n\\end{align}\\]\nwhere \\(\\mathbf{u}_j^{point}\\) and \\(\\mathbf{u}_k^{ray}\\) represent an extreme point and extreme ray, respectively. In addition, \\(\\lambda_j \\geq 0\\) for all \\(j \\in \\mathbf{J}\\) and \\(\\sum_{j \\in \\mathbf{J}}\\lambda_j = 1\\), and \\(\\mu_k \\geq 0\\) for all \\(k \\in \\mathbf{K}\\). It follows that the \\(\\mathbf{DSP}\\) is equivalent to\n\\[\\begin{align}\n\\text{max.} &\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} (\\sum_{j \\in \\mathbf{J}} \\lambda_j \\mathbf{u}_{j}^{point} + \\sum_{k \\in \\mathbf{K}} \\mu_k \\mathbf{u}_k^{ray}) \\\\\n\\text{s.t.} &\\quad \\sum_{j \\in \\mathbf{J}}\\lambda_j = 1 \\\\\n&\\quad \\lambda_j \\geq 0, \\ \\forall j \\in \\mathbf{J} \\\\\n&\\quad \\mu_k \\geq 0, \\ \\forall k \\in \\mathbf{K}\n\\end{align}\\]\nWe can therefore conclude that\n\nThe \\(\\mathbf{DSP}\\) becomes unbounded if any \\(\\mathbf{u}_k^{ray}\\) exists such that \\((\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_k^{ray} &gt; 0\\). Note that an unbounded \\(\\mathbf{DSP}\\) implies an infeasible \\(\\mathbf{SP}\\) and to prevent this from happening, we have to ensure that \\((\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_k^{ray} \\leq 0\\) for all \\(k \\in \\mathbf{K}\\).\nIf an optimal solution to \\(\\mathbf{DSP}\\) exists, it must occur at one of the extreme points. Let \\(g\\) denote the optimal objective value, it follows that \\((\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_j^{point} \\leq g\\) for all \\(j \\in \\mathbf{J}\\).\n\nBased on this idea, the \\(\\mathbf{DSP}\\) can be reformulated as follows:\n\\[\\begin{align}\n\\text{min.} &\\quad g \\\\\n\\text{s.t.} &\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_k^{ray} \\leq 0, \\ \\forall j \\in \\mathbf{J} \\label{bd-feas} \\\\\n&\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_j^{point} \\leq g, \\ \\forall k \\in \\mathbf{K} \\label{bd-opt} \\\\\n&\\quad j \\in \\mathbf{J}, k \\in \\mathbf{K}\n\\end{align}\\]\nConstraints \\(\\eqref{bd-feas}\\) are called Benders feasibility cuts, while constraints \\(\\eqref{bd-opt}\\) are called Benders optimality cuts. Now we are ready to define the Benders Master Problem (\\(\\mathbf{BMP}\\)) as follows:\n\\[\\begin{align}\n    \\text{min.} &\\quad \\mathbf{f}^T \\mathbf{y} + g \\\\\n    \\text{s.t.} &\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_k^{ray} \\leq 0, \\ \\forall j \\in \\mathbf{J} \\\\\n    &\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_j^{point} \\leq g, \\ \\forall k \\in \\mathbf{K} \\\\\n    &\\quad j \\in \\mathbf{J}, k \\in \\mathbf{K}, \\mathbf{y} \\geq 0\n\\end{align}\\]\nTypically \\(J\\) and \\(K\\) are too large to enumerate upfront and we have to work with subsets of them, denoted by \\(J_s\\) and \\(K_s\\), respectively. Hence we have the following Restricted Benders Master Problem (\\(\\mathbf{RBMP}\\)):\n\\[\\begin{align}\n    \\text{min.} &\\quad \\mathbf{f}^T \\mathbf{y} + g \\\\\n    \\text{s.t.} &\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_k^{ray} \\leq 0, \\ \\forall j \\in \\mathbf{J}_s \\\\\n    &\\quad (\\mathbf{b} - \\mathbf{B} \\mathbf{y})^{T} \\mathbf{u}_j^{point} \\leq g, \\ \\forall k \\in \\mathbf{K}_s \\\\\n    &\\quad j \\in \\mathbf{J}, k \\in \\mathbf{K}, \\mathbf{y} \\geq 0\n\\end{align}\\]\n\n\n\n\n\n\nflowchart LR\n   A[Start] --&gt; B{Is}\n    B --&gt;|Yes| C[OK]\n    C --&gt; D[Rethink]\n    D --&gt; B\n    B ----&gt;|No| E[End]\n\n\n\n\nFigure 4.1: Benders decomposition workflow",
    "crumbs": [
      "Benders Decomposition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Benders Decomposition</span>"
    ]
  },
  {
    "objectID": "benders-theory.html#solving-linear-programming-problems-with-benders-decomposition",
    "href": "benders-theory.html#solving-linear-programming-problems-with-benders-decomposition",
    "title": "4  Benders Decomposition",
    "section": "4.2 Solving Linear Programming Problems with Benders Decomposition",
    "text": "4.2 Solving Linear Programming Problems with Benders Decomposition\nIn this section, we use Benders decomposition to solve several linear programming (LP) problems in order to demonstrate the decomposition logic, especially how the restricted Benders master problem interacts with the subproblem in an iterative approach to reach final optimality. Most linear programs could be solved efficiently nowadays by either open source or commercial solvers without resorting to any decomposition approaches. However, by working through the example problems in the following sections, we aim to showcase the implementation details when applying Benders decomposition algorithm on real problems, which helps solidify our understanding of Benders decomposition. Hopefully, by the end of this chapter, we will build up enough intuition as well as hands-on experience such that we are ready to tackle most involved problems in the following chapters.\nIn the following sections, we employ several steps to illustrate the problem solving process of Benders decomposition.\n\nWe will first create two linear programming solvers based on Gurobi and SCIP that can solve any linear programs defined in the standard form. They are used in later section to validate the correctness of the solutions produced by Benders decomposition.\nNext, we use a specific linear program and give the corresponding RBMP and DSP to prepare for the implementations.\nThen, we will solve the example linear program step by step by examining the outputs of the RBMP and DSP to decided the next set of actions.\nFuthermore, a holistic Benders decomposition implementation is then developed to solve the example linear program.\nFollowing the previous step, a more generic Benders decomposition implementation is created.\nThen, we will examine an alternative implementation using Gurobi callback functions.\nWe will also provide an implementation based on SCIP.\nIn the final section, we will do several benchmarking testing.\n\n\n4.2.1 LP solvers based on Gurobi and SCIP\nWe aim to use Benders decomposition to solve several linear programming problems in the following sections. To do that, we intentionally decompose the LP problem under consideration into two sets, one set of complicating variables and the other set containing the remaining variables. In order to validate the correctness of the results obtained by Benders decomposition, we implement two additional ways of solving the target linear programming problems directly. The first option is based on the Gurobi API in python and the other is based on the open source solve SCIP. The two implementations defined here assume the LP problems under consideration follow the below standard form:\n\\[\\begin{align}\n    \\text{min.} &\\quad \\mathbf{c}^T \\mathbf{x} \\\\\n    \\text{s.t.} &\\quad \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\\\\n    &\\quad \\mathbf{x} \\geq 0\n\\end{align}\\]\nListing 4.1 defines a solver for LP problems using Gurobi. It takes three constructor parameters:\n\nobj_coeff: this corresponds to the objective coefficients \\(\\mathbf{c}\\).\nconstr_mat: this refers to the constraint matrix \\(\\mathbf{A}\\).\nrhs: this is the right-hand side \\(\\mathbf{b}\\).\n\nInside the constructor __init__(), a solver environment _env is first created and then used to initialize a model object _model. The input parameters are then used to create decision variables _vars, constraints _constrs and objective function respectively. The optimize() function simply solves the problem and shows the solving status. Finally, the clean_up() function frees up the computing resources.\n\n\n\n\nListing 4.1: A LP solver based on Gurobi\n\n\nimport gurobipy as gp\nfrom gurobipy import GRB\nimport numpy as np\n\nclass LpSolverGurobi:\n    \n    def __init__(self, obj_coeff, constr_mat, rhs, verbose=False):\n        # initialize environment and model\n        self._env = gp.Env('GurobiEnv', empty=True)\n        # self._env.setParam('LogToConsole', 1 if verbose else 0)\n        self._env.setParam('OutputFlag', 1 if verbose else 0)\n        self._env.start()\n        self._model = gp.Model(env=self._env, name='GurobiLpSolver')\n        \n        # prepare data\n        self._obj_coeff = obj_coeff\n        # print(self._obj_coeff)\n        self._constr_mat = constr_mat\n        # print(self._constr_mat)\n        self._rhs = rhs\n        self._num_vars = len(self._obj_coeff)\n        self._num_constrs = len(self._rhs)\n        \n        # create decision variables\n        self._vars = self._model.addMVar(self._num_vars, \n                                         vtype=GRB.CONTINUOUS, \n                                         lb=0)\n        \n        # create constraints\n        self._constrs = self._model.addConstr(\n            self._constr_mat@self._vars == self._rhs\n        )\n        \n        # create objective\n        self._model.setObjective(self._obj_coeff@self._vars, \n                                 GRB.MINIMIZE)\n    \n    def optimize(self, verbose=False):\n        self._model.optimize()\n        if self._model.status == GRB.OPTIMAL:\n            print(f'Optimal solution found!')\n            print(f'Optimal objective = {self._model.objVal:.2f}')\n        elif self._model.status == GRB.UNBOUNDED:\n            print(f'Model is unbounded!')\n        elif self._model.status == GRB.INFEASIBLE:\n            print(f'Model is infeasible!')\n        else:\n            print(f'Unknown error occurred!')\n            \n    def save_model(self, filename):\n        self._model.write(filename)\n    \n    def clean_up(self):\n        self._model.dispose()\n        self._env.dispose()\n\n\n\n\nListing 4.2 presents an LP solver implementation in class LpSolverSCIP using SCIP. The constructor requires the same of parameters as defined in LpSolverGurobi. The model building process is similar with minor changes when required to create decision variables, constraints and the objective function.\n\n\n\n\nListing 4.2: A LP solver based on SCIP\n\n\nimport pyscipopt as scip\nfrom pyscipopt import SCIP_PARAMSETTING\n\nclass LpSolverSCIP:\n    \n    def __init__(self, obj_coeff, constr_mat, rhs, verbose=False):\n        self._model = scip.Model('LpModel')\n        if not verbose:\n            self._model.hideOutput()\n    \n        # create variables\n        self._vars = {\n            i: self._model.addVar(lb=0, vtype='C')\n            for i in range(len(obj_coeff))\n        }\n        \n        # create constraints\n        for c in range(len(rhs)):\n            expr = [\n                constr_mat[c][j] * self._vars.get(j)\n                for j in range(len(obj_coeff))\n            ]\n            self._model.addCons(scip.quicksum(expr) == rhs[c])\n            \n        # create objective\n        obj_expr = [\n            obj_coeff[i] * self._vars.get(i)\n            for i in range(len(obj_coeff))\n        ]\n        self._model.setObjective(scip.quicksum(obj_expr), \"minimize\")\n    \n    def optimize(self):\n        self._model.optimize()\n        status = self._model.getStatus()\n        if status == \"optimal\":\n            print(f'Optimal solution found!')\n            print(f'Optimal objective = {self._model.getObjVal():.2f}')\n        elif status == \"unbounded\":\n            print(f'Model is unbounded!')\n        elif status == \"infeasible\":\n            print(f'Model is infeasible!')\n        else:\n            print(f'Unknown error occurred!')\n\n\n\n\nListing 4.3 generates a LP problem with 20 decision variables and 5 constraints.\n\n\n\n\nListing 4.3: A randomly generated LP problem\n\n\nimport numpy as np\n\nnp.random.seed(42)\nc = np.random.randint(1, 6, size=20)\nA = np.random.randint(-10, 12, size=(5, 20))\nb = np.random.randint(20, 100, size=5)\n\n\n\n\nListing 4.4 solves the generated LP using LpSolverGurobi and the solver output shows that an optimal solution was found with objective value of 36.90.\n\n\n\n\nListing 4.4: Solving the generated LP with Gurobi\n\n\nlpsolver_gurobi = LpSolverGurobi(obj_coeff=c, constr_mat=A, rhs=b)\nlpsolver_gurobi.optimize()\n\n\n\n\nOptimal solution found!\nOptimal objective = 36.90\n\n\nListing 4.5 solves the same LP problem using SCIP and not surprisingly, the same optimal objective value was found. This is not exciting, as it only indicates that the two solvers agree on the optimal solution on such a small LP problem as expected. However, they will become more useful in the following sections when we use them to validate our Benders decomposition results.\n\n\n\n\nListing 4.5: Solving the generated LP with SCIP\n\n\nlpsolver_scip = LpSolverSCIP(obj_coeff=c, constr_mat=A, rhs=b)\nlpsolver_scip.optimize()\n\n\n\n\nOptimal solution found!\nOptimal objective = 36.90\n\n\n\n\n4.2.2 A serious LP problem that cannot wait to be decomposed!\nWith the validation tools available for use, we are ready to solve some serious LP problems using Benders decomposition! What we have below is a LP problem with five decision variables, three of which are denoted by \\(\\mathbf{x} = (x_1, x_2, x_3)\\) and the remaining two variables are denoted by \\(\\mathbf{y} = (y_1, y_2)\\). We assume that \\(\\mathbf{y}\\) are the complicating variables.\n\\[\\begin{align*}\n    \\text{min.} &\\quad 8x_1 + 12x_2 +10x_3 + 15y_1 + 18y_2 \\\\\n    \\text{s.t.} &\\quad 2x_1 + 3x_2 + 2x_3 + 4y_1 + 5y_2 = 300 \\\\\n    &\\quad 4x_1 + 2x_2 + 3x_3 + 2y_1 + 3y_2 = 220 \\\\\n    &\\quad x_i \\geq 0, \\ \\forall i = 1, \\cdots, 3 \\\\\n    &\\quad y_i \\geq 0, \\ \\forall j = 1, 2\n\\end{align*}\\]\nAccording to the standard LP form presented in the previous section, \\(\\mathbf{c}^T = (8, 12, 10)\\), \\(\\mathbf{f}^T = (15, 18)\\) and \\(\\mathbf{b}^T = (300, 220)\\). In addition,\n\\[\\begin{equation*}\n\\mathbf{A} =\n\\begin{bmatrix}\n    2 & 3 & 2 \\\\\n    4 & 2 & 3 \\\\\n\\end{bmatrix}\n\\qquad\n\\mathbf{B} =\n\\begin{bmatrix}\n    4 & 5 \\\\\n    2 & 3 \\\\\n\\end{bmatrix}\n\\end{equation*}\\]\nListing 4.6 solves the LP problem using the two solvers define above. Both solvers confirm the optimal objective value is 1091.43. With this information in mind, we will apply Benders decomposition to see if the same optimal solution could be identified or not.\n\n\n\n\nListing 4.6: Solve the LP problem with Gurobi and SCIP\n\n\nc = np.array([8, 12, 10])\nf = np.array([15, 18])\nobj_coeff = np.concatenate([c, f])\n\nA = np.array([[2, 3, 2],\n     [4, 2, 3]])\nB = np.array([[4, 5],\n     [2, 3]])\nconstr_mat = np.concatenate([A, B], axis=1)\n\nrhs = np.array([300, 220])\n\nlpsolver_gurobi = LpSolverGurobi(obj_coeff, constr_mat, rhs, verbose=False)\nlpsolver_gurobi.optimize()\n# Optimal objective = 1091.43\n\nlpsolver_scip = LpSolverSCIP(obj_coeff, constr_mat, rhs, verbose=False)\nlpsolver_scip.optimize()\n# Optimal objective = 1091.43\n\n\n\n\nOptimal solution found!\nOptimal objective = 1091.43\nOptimal solution found!\nOptimal objective = 1091.43\n\n\n\n\n4.2.3 Benders decomposition formulations\nWith \\(\\mathbf{y}\\) being the complicating variable, we state the Benders subproblem (SP) below for the \\(\\mathbf{y}\\) assuming fixed values \\(\\mathbf{\\bar{y}} = (\\bar{y_1}, \\bar{y_2})\\):\n\\[\\begin{align*}\n    \\text{min.} &\\quad 8x_1 + 12x_2 +10x_3 \\\\\n    \\text{s.t.} &\\quad 2x_1 + 3x_2 + 2x_3 = 300 - 4\\bar{y_1} - 5\\bar{y_2} \\\\\n    &\\quad 4x_1 + 2x_2 + 3x_3 = 220 - 2\\bar{y_1} - 3\\bar{y_2} \\\\\n    &\\quad x_i \\geq 0, \\ \\forall i = 1, \\cdots, 3\n\\end{align*}\\]\nWe define the dual variable \\(\\mathbf{u} = (u_1, u_2)\\) to associate with the constraints in the (SP). The dual subproblem (DSP) could then be stated as follows:\n\\[\\begin{align*}\n    \\text{max.} &\\quad (300 - 4\\bar{y_1} - 5\\bar{y_2}) u_1 + (220 - 2\\bar{y_1} - 3\\bar{y_2}) u_2 \\\\\n    \\text{s.t.} &\\quad 2u_1 + 4u_2 \\leq 8\\\\\n    &\\quad 3u_1 + 2u_2 \\leq 12 \\\\\n    &\\quad 2u_1 + 3u_2 \\leq 10 \\\\\n    &\\quad u_1, u_2\\  \\text{unrestricted}\n\\end{align*}\\]\nThe (RBMP) can be stated as below. Note that \\(\\mathbf{u} = (0, 0)\\) is a feasible solution to (DSP) and the corresponding objective value is 0, which is the reason we restrict the variable \\(g\\) to be nonnegative.\n\\[\\begin{align*}\n    \\text{min.} &\\quad 15 y_1 + 18 y_2 + g \\\\\n    \\text{s.t.} &\\quad  y_1, y_2 \\geq 0 \\\\\n    &\\quad g \\geq 0\n\\end{align*}\\]\n\n\n4.2.4 Benders decomposition step by step\nBenders decomposition defines a problem solving process in which the restricted Benders master problem and the dual subproblem interact iteratively to identify the optimal solution or conclude infeasibility/unboundedness. To facilitate our understanding of the process, we demonstrate in this section the workings of Benders decomposition by solving the target LP problem step by step.\nListing 4.7 shows the codes that initialize the lower bound lb, upper bound ub and threshold value eps. Furthermore, the restricted Benders master problem rbmp is created with three variables and a minimizing objective function. Note that no constraints are yet included in the model at this moment.\n\n\n\n\nListing 4.7: Gurobi solver setup and restricted master problem initialization\n\n\nimport numpy as np\nimport gurobipy as gp\nfrom gurobipy import GRB\n\n# initialize lower/upper bounds and threshold value\nlb = -GRB.INFINITY\nub = GRB.INFINITY\neps = 1.0e-5\n\n# create restricted Benders master problem\nenv = gp.Env('benders', empty=True)\nenv.setParam('OutputFlag', 0)\nenv.start()\nrbmp = gp.Model(env=env, name='RBMP')\n\n# create decision variables\ny1 = rbmp.addVar(vtype=GRB.CONTINUOUS, lb=0, name='y1')\ny2 = rbmp.addVar(vtype=GRB.CONTINUOUS, lb=0, name='y2')\ng = rbmp.addVar(vtype=GRB.CONTINUOUS, lb=0, name='g')\n\n# create objective\nrbmp.setObjective(15*y1 + 18*y2 + g, GRB.MINIMIZE)\n\n\n\n\nListing 4.8 initializes the Benders subproblem with two decision variables and three constraints.\n\n\n\n\nListing 4.8: Dual subproblem initialization\n\n\n# create dual subproblem\ndsp = gp.Model(env=env, name='DSP')\n\n# create decision variables\nu1 = dsp.addVar(vtype=GRB.CONTINUOUS,\n                lb=-GRB.INFINITY,\n                ub=GRB.INFINITY,\n                name='u1')\nu2 = dsp.addVar(vtype=GRB.CONTINUOUS,\n                lb=-GRB.INFINITY,\n                ub=GRB.INFINITY,\n                name='u2')\n\n# create objective function\ndsp.setObjective(300*u1 + 220*u2)\n\n# create constraints\ndsp.addConstr(2*u1 + 4*u2 &lt;= 8, name='c1')\ndsp.addConstr(3*u1 + 2*u2 &lt;= 12, name='c2')\ndsp.addConstr(2*u1 + 3*u2 &lt;= 10, name='c3')\n\ndsp.update()\n\n\n\n\nIn Listing 4.9, we solve the (RBMP) for the first time. It has an optimal solution with \\((\\bar{y_1}, \\bar{y_2}, \\bar{g}) = (0, 0, 0)\\) and optimal objective value of 0. This is expected as all the variables assume their minimal possible values in order to minimize the objective function. This objective value also serves as the new lower bound.\n\n\n\n\nListing 4.9: Iteration 1 - solving the restricted Benders master problem\n\n\nrbmp.optimize()\n\nif rbmp.status == GRB.OPTIMAL:\n    print(f'Optimal solution found! Objective value = {rbmp.objVal:.2f}')\n    \n    y1_opt, y2_opt, g_opt = y1.X, y2.X, g.X\n    lb = np.max([lb, rbmp.objVal])\n    \n    print(f'(y1, y2, g) = ({y1_opt:.2f}, {y2_opt:.2f}, {g_opt:.2f})')\n    print(f'lb={lb}, ub={ub}')\nelif rbmp.status == GRB.INFEASIBLE:\n    print(f'original problem is infeasible!')\n\n\n\n\nOptimal solution found! Objective value = 0.00\n(y1, y2, g) = (0.00, 0.00, 0.00)\nlb=0.0, ub=1e+100\n\n\nGiven that \\((\\bar{y_1}, \\bar{y_2}, \\bar{g}) = (0, 0, 0)\\), we now feed the values of \\(\\bar{y_1}\\) and \\(\\bar{y_2}\\) into the Benders dual subproblem (DSP) by updating its objective function, as shown in Listing 4.10:\n\n\n\n\nListing 4.10: Iteration 1 - solving the dual subproblem\n\n\n# update objective function\ndsp.setObjective((300-4*y1_opt-5*y2_opt)*u1 + \n                 (220-2*y1_opt-3*y2_opt)*u2, \n                 GRB.MAXIMIZE)\ndsp.update()\ndsp.optimize()\n\nif dsp.status == GRB.OPTIMAL:\n    u1_opt, u2_opt = u1.X, u2.X\n    \n    print(f'Optimal objective = {dsp.objVal:.2f}')\n    print(f'(u1, u2) = ({u1_opt:.2f}, {u2_opt:.2f})')\n    ub = np.min([ub, 15*y1_opt + 18*y2_opt + dsp.objVal])\n    print(f'lb={lb}, ub={ub}')\n\n\n\n\nOptimal objective = 1200.00\n(u1, u2) = (4.00, 0.00)\nlb=0.0, ub=1200.0\n\n\nWe see that the dual subproblem has an optimal solution. The upper bound ub is also updated. Since the optimal objective value of the subproblem turns out to be 1200 and is greater than \\(\\bar{g} = 0\\), which implies that an optimality cut is needed to make sure that the variable \\(g\\) in the restricted Benders master problem reflects this newly obtained information from the subproblem.\nIn Listing 4.11, the new optimality cut is added to the (RBMP), which is then solved to optimality.\n\n\n\n\nListing 4.11: Iteration 2 - solving the restricted Benders master problem\n\n\n# add optimality cut\nrbmp.addConstr((300-4*y1-5*y2)*u1_opt \n               + (220-2*y1-3*y2)*u2_opt &lt;= g, \n               name='c1')\nrbmp.update()\nrbmp.optimize()\n\nif rbmp.status == GRB.OPTIMAL:\n    print(f'Optimal solution found! Objective value = {rbmp.objVal:.2f}')\n    \n    y1_opt, y2_opt, g_opt = y1.X, y2.X, g.X\n    lb = np.max([lb, rbmp.objVal])\n    \n    print(f'(y1, y2, g) = ({y1_opt:.2f}, {y2_opt:.2f}, {g_opt:.2f})')\n    print(f'lb={lb}, ub={ub}')\nelif rbmp.status == GRB.INFEASIBLE:\n    print(f'original problem is infeasible!')\n\n\n\n\nOptimal solution found! Objective value = 1080.00\n(y1, y2, g) = (0.00, 60.00, 0.00)\nlb=1080.0, ub=1200.0\n\n\nArmed with the optimal solution \\((\\bar{y_1}, \\bar{y_2}, \\bar{g}) = (0, 60, 0)\\), Listing 4.12 updates the objective function of the (DSP) and obtains its optimal solution.\n\n\n\n\nListing 4.12: Iteration 2 - solving the dual subproblem\n\n\n# update objective function\ndsp.setObjective((300-4*y1_opt-5*y2_opt)*u1 \n                 + (220-2*y1_opt-3*y2_opt)*u2, \n                 GRB.MAXIMIZE)\ndsp.update()\ndsp.optimize()\n\nif dsp.status == GRB.OPTIMAL:\n    u1_opt, u2_opt = u1.X, u2.X\n    \n    print(f'Optimal objective = {dsp.objVal:.2f}')\n    print(f'(u1, u2) = ({u1_opt:.2f}, {u2_opt:.2f})')\n    ub = np.min([ub, 15*y1_opt + 18*y2_opt + dsp.objVal])\n    print(f'lb={lb}, ub={ub:.2f}')\nelif dsp.Status == GRB.UNBOUNDED:\n    print(f'DSP is unbounded!')\n    u1_ray = u1.UnbdRay\n    u2_ray = u2.UnbdRay\n    print(f'retrieve extreme ray (u1, u2) = ({u1_ray}, {u2_ray})')\nelse:\n    print(f'DSP solve error')\n\n\n\n\nDSP is unbounded!\nretrieve extreme ray (u1, u2) = (-2.0, 1.0)\n\n\nSince the dual subproblem is unbounded, a feasibility cut is further needed. In Listing 4.13, we add the new cut and solve the restricted Benders master problem again.\n\n\n\n\nListing 4.13: Iteration 3 - solving the restricted Benders master problem\n\n\n# add optimality cut\nrbmp.addConstr((300-4*y1-5*y2)*u1_ray\n               + (220-2*y1-3*y2)*u2_ray &lt;= 0, \n               name='c2')\nrbmp.update()\nrbmp.optimize()\n\nif rbmp.status == GRB.OPTIMAL:\n    print(f'Optimal solution found! Objective value = {rbmp.objVal:.2f}')\n    \n    y1_opt, y2_opt, g_opt = y1.X, y2.X, g.X\n    lb = np.max([lb, rbmp.objVal])\n    \n    print(f'(y1, y2, g) = ({y1_opt:.2f}, {y2_opt:.2f}, {g_opt:.2f})')\n    print(f'lb={lb:.2f}, ub={ub:.2f}')\nelif rbmp.status == GRB.INFEASIBLE:\n    print(f'original problem is infeasible!')\n\n\n\n\nOptimal solution found! Objective value = 1091.43\n(y1, y2, g) = (0.00, 54.29, 114.29)\nlb=1091.43, ub=1200.00\n\n\nNote that a new lower bound is obtained after solving the master problem. Since there is still a large gap between the lower bound and upper bound, we continue solving the subproblem in Listing 4.14.\n\n\n\n\nListing 4.14: Iteration 3 - solving the dual subproblem\n\n\n# update objective function\ndsp.setObjective((300-4*y1_opt-5*y2_opt)*u1 \n                 + (220-2*y1_opt-3*y2_opt)*u2, \n                 GRB.MAXIMIZE)\ndsp.update()\ndsp.optimize()\n\nif dsp.status == GRB.OPTIMAL:\n    u1_opt, u2_opt = u1.X, u2.X\n    \n    print(f'Optimal objective = {dsp.objVal:.2f}')\n    print(f'(u1, u2) = ({u1_opt:.2f}, {u2_opt:.2f})')\n    ub = np.min([ub, 15*y1_opt + 18*y2_opt + dsp.objVal])\n    print(f'lb={lb:.2f}, ub={ub:.2f}')\n\n\n\n\nOptimal objective = 114.29\n(u1, u2) = (4.00, 0.00)\nlb=1091.43, ub=1091.43\n\n\nNow that the difference between lb and ub is less than the preset threshold eps, we conclude that an optimal solution is reached and the computation resources are freed up.\n\n# release resources\nrbmp.dispose()\ndsp.dispose()\nenv.dispose()\n\n\n\n4.2.5 Benders decomposition automated\nIt typically takes Benders decomposition many iterations to reach optimality or conclude infeasibility/unboundedness. In this section, we put everything we have learned from the manual approach above into an automatic workflow.\nListing 4.15 defines an Enum class that specifies four possible optimization statuses. The meanings of these statuses are self-explanatory from their corresponding names and further explanations are omitted here.\n\n\n\n\nListing 4.15: Optimization status\n\n\nimport gurobipy as gp\nfrom gurobipy import GRB\nimport numpy as np\nfrom enum import Enum\n\nclass OptStatus(Enum):\n    OPTIMAL = 0\n    UNBOUNDED = 1\n    INFEASIBLE = 2\n    ERROR = 3\n\n\n\n\nListing 4.16 defines a ManualBendersMasterSolver class that models the (RBMP). Its constructor contains the variable and objective function definitions. The ability to take in either feasibility or optimality cuts is implemented in separate functions add_feasibility_cut() and add_optimality_cut(), respectively. The solve() function is responsible for optimizing the model and retrieve the optimal solution if any.\n\n\n\n\nListing 4.16: Restricted Benders master model\n\n\nclass ManualBendersMasterSolver:\n    \n    def __init__(self, env):\n        self._model = gp.Model(env=env, name='RBMP')\n        \n        # create decision variables\n        self._y1 = self._model.addVar(vtype=GRB.CONTINUOUS, \n                                      lb=0, name='y1')\n        self._y2 = self._model.addVar(vtype=GRB.CONTINUOUS, \n                                      lb=0, name='y2')\n        self._g = self._model.addVar(vtype=GRB.CONTINUOUS, \n                                     lb=0, name='g')\n\n        # create objective\n        self._model.setObjective(15*self._y1+18*self._y2+self._g, \n                                 GRB.MINIMIZE)\n        \n        self._opt_obj = None\n        self._opt_y1 = None\n        self._opt_y2 = None\n        self._opt_g = None\n        \n    def solve(self) -&gt; OptStatus:\n        print('-' * 50)\n        print(f'Start solving master problem.')\n        self._model.optimize()\n        \n        opt_status = None\n        if self._model.status == GRB.OPTIMAL:\n            opt_status = OptStatus.OPTIMAL\n            self._opt_obj = self._model.objVal\n            self._opt_y1 = self._y1.X\n            self._opt_y2 = self._y2.X\n            self._opt_g = self._g.X\n            print(f'\\tmaster problem is optimal.')\n            print(f'\\topt_obj={self._opt_obj:.2f}')\n            print(f'\\topt_y1={self._opt_y1:.2f}, opt_y2={self._opt_y2:.2f}')\n            print(f'\\topt_g={self._opt_g:.2f}')\n        elif self._model.status == GRB.INFEASIBLE:\n            print(f'\\tmaster problem is infeasible.')\n            opt_status = OptStatus.INFEASIBLE\n        else:\n            print(f'\\tmaster problem encountered error.')\n            opt_status = OptStatus.ERROR\n        \n        print(f'Finish solving master problem.') \n        print('-' * 50)\n        return opt_status\n    \n    def add_feasibility_cut(self, ray_u1, ray_u2) -&gt; None:\n        self._model.addConstr((300-4*self._y1-5*self._y2)*ray_u1 + \n                              (220-2*self._y1-3*self._y2)*ray_u2 &lt;= \n                              0)\n        print(f'Benders feasibility cut added!')\n    \n    def add_optimality_cut(self, opt_u1, opt_u2) -&gt; None:\n        self._model.addConstr((300-4*self._y1-5*self._y2)*opt_u1 + \n                              (220-2*self._y1-3*self._y2)*opt_u2 &lt;= \n                              self._g)\n        print(f'Benders optimality cut added!')\n    \n    def clean_up(self):\n        self._model.dispose()\n        \n    @property\n    def opt_obj(self):\n        return self._opt_obj\n    \n    @property\n    def opt_y1(self):\n        return self._opt_y1\n    \n    @property\n    def opt_y2(self):\n        return self._opt_y2\n    \n    @property\n    def opt_g(self):\n        return self._g\n\n\n\n\nListing 4.17 defines the Benders dual subproblem in a similar fashion. Notice that the update_objective() function is used to set an updated objective function based on the optimal solution identified in the restricted Benders master problem.\n\n\n\n\nListing 4.17: Dual subproblem model\n\n\nclass ManualBendersSubprobSolver:\n    \n    def __init__(self, env):\n        self._model = gp.Model(env=env, name='DSP')\n        \n        # create decision variables\n        self._u1 = self._model.addVar(vtype=GRB.CONTINUOUS,\n                                      lb=-GRB.INFINITY,\n                                      ub=GRB.INFINITY,\n                                      name='u1')\n        self._u2 = self._model.addVar(vtype=GRB.CONTINUOUS,\n                                      lb=-GRB.INFINITY,\n                                      ub=GRB.INFINITY,\n                                      name='u2')\n        \n        # create constraints\n        self._model.addConstr(2*self._u1+4*self._u2 &lt;= 8, name='c1')\n        self._model.addConstr(3*self._u1+2*self._u2 &lt;= 12, name='c2')\n        self._model.addConstr(2*self._u1+3*self._u2 &lt;= 10, name='c3')\n        \n        self._model.setObjective(1, GRB.MAXIMIZE)\n        self._model.update()\n        \n        self._opt_obj = None\n        self._opt_u1 = None\n        self._opt_u2 = None\n        self._ray_u1 = None\n        self._ray_u2 = None\n    \n    def solve(self):\n        print('-' * 50)\n        print(f'Start solving dual subproblem.')\n        self._model.optimize()\n        \n        status = None\n        if self._model.status == GRB.OPTIMAL:\n            self._opt_obj = self._model.objVal\n            self._opt_u1 = self._u1.X\n            self._opt_u2 = self._u2.X\n            status = OptStatus.OPTIMAL\n            print(f'\\tdual subproblem is optimal.')\n            print(f'\\topt_obj={self._opt_obj:.2f}')\n            print(f'\\topt_y1={self._opt_u1:.2f}, opt_y2={self._opt_u2:.2f}')\n        elif self._model.status == GRB.UNBOUNDED:\n            status = OptStatus.UNBOUNDED\n            print(f'\\tdual subproblem is unbounded!')\n            self._ray_u1 = self._u1.UnbdRay\n            self._ray_u2 = self._u2.UnbdRay\n            print(f'\\textreme ray (u1, u2) = ({self._ray_u1}, {self._ray_u2})')\n        else:\n            status = OptStatus.ERROR\n        \n        print(f'Finish solving dual subproblem.')\n        print('-' * 50)\n        return status\n    \n    def update_objective(self, opt_y1, opt_y2):\n        self._model.setObjective(\n            (300-4*opt_y1-5*opt_y2)*self._u1 + \n            (220-2*opt_y1-3*opt_y2)*self._u2, \n            GRB.MAXIMIZE)\n        print(f'dual subproblem objective updated!')\n    \n    def clean_up(self):\n        self._model.dispose()\n        \n    @property\n    def opt_obj(self):\n        return self._opt_obj\n    \n    @property\n    def opt_u1(self):\n        return self._opt_u1\n    \n    @property\n    def opt_u2(self):\n        return self._opt_u2\n    \n    @property\n    def ray_u1(self):\n        return self._ray_u1\n    \n    @property\n    def ray_u2(self):\n        return self._ray_u2\n\n\n\n\nListing 4.18 shows the control flow of Benders decomposition. The main logic is stated as a while loop, in which the master problem and dual subproblem are solved sequentially within each iteration. Depending on whether the subproblem is optimal or unbounded, an optimality or feasibility cut is added to the master problem. The process continues until the gap between the lower bound and the upper bound is within a certain threshold.\n\n\n\n\nListing 4.18: Benders decomposition control flow\n\n\nclass ManualBendersDecomposition:\n    \n    def __init__(self, master_solver, dual_subprob_solver):\n        self._master_solver = master_solver\n        self._dual_subprob_solver = dual_subprob_solver\n        \n    \n    def optimize(self) -&gt; OptStatus:\n        eps = 1.0e-5\n        lb = -np.inf\n        ub = np.inf\n        \n        iter = 1\n        while True:\n            print(f\"\\nIteration: {iter}\")\n            iter += 1\n            # solve master problem\n            master_status = self._master_solver.solve()\n            if master_status == OptStatus.INFEASIBLE:\n                return OptStatus.INFEASIBLE\n            \n            # update lower bound\n            lb = np.max([lb, self._master_solver.opt_obj])\n            print(f'Bounds: lb={lb:.2f}, ub={ub:.2f}')\n            \n            opt_y1 = self._master_solver.opt_y1\n            opt_y2 = self._master_solver.opt_y2\n            \n            # solve subproblem\n            self._dual_subprob_solver.update_objective(opt_y1, opt_y2)\n            dsp_status = self._dual_subprob_solver.solve()\n            \n            if dsp_status == OptStatus.OPTIMAL:\n                # update upper bound\n                opt_obj = self._dual_subprob_solver.opt_obj\n                ub = np.min([ub, 15*opt_y1 + 18*opt_y2 + opt_obj])\n                print(f'Bounds: lb={lb:.2f}, ub={ub:.2f}')\n                \n                if ub - lb &lt;= eps:\n                    break\n                \n                opt_u1 = self._dual_subprob_solver.opt_u1\n                opt_u2 = self._dual_subprob_solver.opt_u2\n                self._master_solver.add_optimality_cut(opt_u1, opt_u2) \n            elif dsp_status == OptStatus.UNBOUNDED:\n                ray_u1 = self._dual_subprob_solver.ray_u1\n                ray_u2 = self._dual_subprob_solver.ray_u2\n                self._master_solver.add_feasibility_cut(ray_u1, ray_u2) \n            \n\n\n\n\nListing 4.19 solves the LP problem using the wholesome Benders solver. The optimal solution agrees with the solution obtained in the manual approach.\n\n\n\n\nListing 4.19: Solving the LP problem using Benders decomposition\n\n\nenv = gp.Env('benders', empty=True)\nenv.setParam(\"OutputFlag\",0)\nenv.start()\nmaster_solver = ManualBendersMasterSolver(env)\ndual_subprob_solver = ManualBendersSubprobSolver(env)\n\nbenders_decomposition = ManualBendersDecomposition(master_solver, dual_subprob_solver)\nbenders_decomposition.optimize()\n\n\n\n\n\nIteration: 1\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=0.00\n    opt_y1=0.00, opt_y2=0.00\n    opt_g=0.00\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=0.00, ub=inf\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\n    dual subproblem is optimal.\n    opt_obj=1200.00\n    opt_y1=4.00, opt_y2=0.00\nFinish solving dual subproblem.\n--------------------------------------------------\nBounds: lb=0.00, ub=1200.00\nBenders optimality cut added!\n\nIteration: 2\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=1080.00\n    opt_y1=0.00, opt_y2=60.00\n    opt_g=0.00\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=1080.00, ub=1200.00\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\n    dual subproblem is unbounded!\n    extreme ray (u1, u2) = (-2.0, 1.0)\nFinish solving dual subproblem.\n--------------------------------------------------\nBenders feasibility cut added!\n\nIteration: 3\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=1091.43\n    opt_y1=0.00, opt_y2=54.29\n    opt_g=114.29\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=1091.43, ub=1200.00\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\n    dual subproblem is optimal.\n    opt_obj=114.29\n    opt_y1=4.00, opt_y2=0.00\nFinish solving dual subproblem.\n--------------------------------------------------\nBounds: lb=1091.43, ub=1091.43\n\n\n\n\n4.2.6 Benders decomposition - design and implementation\nThe Benders decomposition algorithm we put together in the last section is a big step towards automating the interaction between the master problem optimizer and the dual subproblem optimizer. However, it is still limited in that both optimizers are tied to a specific problem instance. Even a slight change in the instance data requires an updated optimizer implementation. Ideally, we would like to to have an algorithm that could solve various LP problems as long as they follow the same form.\nIn addition, we might want to have the flexibility to switch to different solvers within the master and dual subproblem optimizers. A good algorithm design should allow alternative implementations with minimal impact on the overall algorithm structure.\nWith these needs in mind, in this section, we aim to design a Benders decomposition algorithm that can solve any LP problems following a standard form and allow various implementations in both the master problem and dual subproblem optimizers.\nWe develop the algorithm in three steps. First, we present a Benders decomposition algorithm design that focuses on the overall algorithm workflow and only the abstract implementations of the master problem and dual subproblem optimizers. Next, an implementation of the Benders decomposition based on Gurobi is demonstrated. Lastly, an alternative implementation based on the open source solver SCIP is illustrated.\n\n4.2.6.1 Benders decomposition algorithm design\nWe could see from the previous sections that Benders decomposition involves three key components:\n\nAn optimizer that solves the master problem\nAn optimizer that solves the dual subproblem\nAn orchestrator that dictates the interaction between the two optimizers\n\nTo be able to solve LP problems of various sizes, both the master and dual subproblem optimizers must take a generic form and not be tied to a fixed number of various and/or constraints. Furthermore, to be able to switch to different solvers, both optimizers need to conform to a common interface.\nTo this end, Listing 4.21 defines a base class for master problem optimizers. The constructor __init__() takes three inputs, namely, objective coefficients, constraint matrix and the right-hand side. Any concrete implementation of the base class is responsible for constructing a model from these three input values using solver-specific modeling languages. The base class also defines several other key functions:\n\nsolve(): this is the function that invokes solver-specific optimization process and saves the corresponding optimization results.\nadd_feasibility_cut(): this function takes an extreme ray identified by the dual subproblem optimizer and adds a feasibility cut to the master problem.\nadd_optimality_cut(): this function takes an optimal solution identified by the dual subproblem optimizer and adds an optimality cut to the master problem.\nopt_obj_val(): this function returns the optimal objective value obtained.\nopt_val_for_complicating_vars(): this function returns the optimal solution values for all the complicating decision variables.\nopt_val_for_surrogate_var(): this function returns the optimal value of the surrogate variable.\n\n\n\n\n\nListing 4.20: Base class for restricted master problem implementations\n\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nimport numpy as np\n\nclass BendersMasterOptimizer(ABC):\n    \"\"\"base class for master solver implementation\n\n    Args:\n        ABC (ABCMeta): helper class\n    \"\"\"\n    @abstractmethod\n    def __init__(self, objective_coefficients: np.array, \n                 constraint_matrix: np.array, \n                 right_hand_side: np.array):\n        \"\"\"constructor for master problem model initialization.\n        Note that two types of variables will be created:\n        - the complicating variables\n        - the surrogate variable\n\n        Args:\n            objective_coefficients (np.array): an array of size n that \n                defines the coefficient value for each variable in the \n                master problem objective function.\n            constraint_matrix (np.array): a matrix of size m * n that \n                defines the constraint coefficients.\n            right_hand_side (np.array): an array of size n that \n                defines the right hand side for each constraint.\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def solve(self) -&gt; OptStatus:\n        \"\"\"solve the problem and return optimization status\n\n        Returns:\n            OptStatus: an enum object\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def add_feasibility_cut(self, extreme_ray: Dict[int, float]) -&gt; None:\n        \"\"\"add feasibility cut.\n\n        Args:\n            extreme_ray (Dict[int, float]): a mapping between variable key \n                and extreme ray element. For example:\n                extreme_ray = {\n                    0: 1.0,\n                    1: 2.0\n                }\n                It is assumed that the key type is integer.\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def add_optimality_cut(self, opt_sol: Dict[int, float]) -&gt; None:\n        \"\"\"add optimality cut.\n\n        Args:\n            opt_sol (Dict[int, float]): a mapping between variable key \n                and optimal solution element. For example:\n                opt_sol = {\n                    0: 1.0,\n                    1: 2.0\n                }\n                It is assumed that the key type is integer.\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def opt_obj_val(self) -&gt; float:\n        \"\"\"return the optimal objective value if exists\n\n        Returns:\n            float: objective value\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def opt_obj_val_comp(self) -&gt; float:\n        \"\"\"return the optimal objective value for the complicating variables\n\n        Returns:\n            float: objective value for the complicating variables\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def opt_val_for_complicating_vars(self) -&gt; Dict[int, float]:\n        \"\"\"return the optimal solution values for complicating variables\n\n        Returns:\n            Dict[int, float]: mapping between variable key and optimal value.\n            For example, opt_val = {\n                0: 2.0,\n                1: 3.0\n            }\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def opt_val_for_surrogate_var(self) -&gt; float:\n        \"\"\"return the optimal value for the surrogate variable\n\n        Returns:\n            float: optimal value for the surrogate variable\n        \"\"\"\n        raise NotImplementedError\n\n\n\n\nSimilarly, Listing 4.21 presents a base class for dual subproblem optimizers. The constructor __init__() takes the objective coefficients and constraint matrix that correspond to the variables in the subproblem. These information are required to create variables and constraints for the dual subproblem. However, the objective function will not be instantiated without the optimal solution of the restricted master problem. This base class also contains several other key functions:\n\nsolve(): this is the function that calls solver-specific procedure to solve the underlying dual subproblem.\nupdate_objective(): this function takes the optimal solution obtained by the master problem optimizer and updates the objective function for the dual subproblem.\nopt_obj_val(): this function returns the optimal objective values identified by the optimizer.\nopt_sol(): this function returns the optimal solution identified by the optimizer.\nextreme_ray(): this function returns the extreme ray identified by the optimizer.\n\n\n\n\n\nListing 4.21: Base class for restricted master problem implementations\n\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict\nimport numpy as np\n\nclass BendersDspOptimizer(ABC):\n    \"\"\"base class for dual subproblem implementation\n\n    Args:\n        ABC (ABCMeta): helper class\n    \"\"\"\n    \n    @abstractmethod\n    def __init__(self, objective_coefficients: np.array, \n                 constraint_matrix: np.array):\n        \"\"\"constructor for dual subproblem model initialization.\n\n        Args:\n            objective_coefficients (np.array): an array of size m that \n                represents the coefficient value for each variable in the \n                original problem objective function.\n            constraint_matrix (np.array): a matrix of size m * n that \n                defines the constraint coefficients in the original problem.\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def solve(self) -&gt; OptStatus:\n        \"\"\"solve the problem and return optimization status\n\n        Returns:\n            OptStatus: an enum object\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def update_objective(self, opt_sol_rbmp: Dict[int, float],\n                         constraint_matrix_rbmp: np.array,\n                         right_hand_side_rbmp: np.array) -&gt; None:\n        \"\"\"update the objective function for the dual subproblem.\n\n        Args:\n            opt_sol_rbmp (Dict[int, float]): optimal solution of the \n                restricted master problem\n            constraint_matrix_rbmp (np.array): constraint matrix \n                associated with the complicating variables in the \n                master problem\n            right_hand_side_rbmp (np.array): right-hand side of \n                the original problem\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def opt_obj_val(self) -&gt; float:\n        \"\"\"return the optimal objective value if exists\n\n        Returns:\n            float: objective value\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def opt_sol(self) -&gt; Dict[int, float]:\n        \"\"\"return the optimal solution values\n\n        Returns:\n            Dict[int, float]: mapping between variable key and optimal value.\n            For example, opt_sol = {\n                0: 2.0,\n                1: 4.0\n            }\n        \"\"\"\n        raise NotImplementedError\n    \n    @abstractmethod\n    def extreme_ray(self) -&gt; Dict[int, float]:\n        \"\"\"return the identified extreme ray\n\n        Returns:\n            Dict[int, float]: mapping between variable key and ray element.\n            For example, extreme_ray = {\n                0: 3.5,\n                1: 6.0\n            }\n        \"\"\"\n        raise NotImplementedError\n\n\n\n\n\n\n\n\nListing 4.22: Generic Benders decomposition for LP problems\n\n\nclass BendersOptimizerConsole:\n    \n    def __init__(self, master_optimizer: BendersMasterOptimizer, \n                 dsp_optimizer: BendersDspOptimizer):\n        self._master_optimizer = master_optimizer\n        self._dsp_optimizer = dsp_optimizer\n    \n    def optimize(self, verbose=False) -&gt; OptStatus:\n        eps = 1.0e-5\n        lb = -np.inf\n        ub = np.inf\n        \n        iter = 0\n        while True:\n            iter += 1\n            if verbose: \n                print(f'\\nIteration: {iter}')\n                \n            # solve master problem\n            master_status = self._master_optimizer.solve()\n            if master_status == OptStatus.INFEASIBLE:\n                if verbose:\n                    print(f'Model is infeasible!')\n                return OptStatus.INFEASIBLE\n            \n            # update lower bound\n            lb = np.max([lb, self._master_optimizer.opt_obj_val])\n            if verbose:\n                print(f'Bounds: lb={lb:.2f}, ub={ub:.2f}')\n            \n            # solve subproblem\n            opt_val_comp = self._master_optimizer.opt_val_for_complicating_vars\n            self._dsp_optimizer.update_objective(opt_val_comp)\n            dsp_status = self._dsp_optimizer.solve()\n            \n            if dsp_status == OptStatus.OPTIMAL:\n                if verbose:\n                    print(f'DSP is optimal!')\n                # update upper bound\n                opt_obj = self._dsp_optimizer.opt_obj_val                \n                opt_obj_val_comp = self._master_optimizer.opt_obj_val_comp\n                ub = np.min([ub, opt_obj_val_comp + opt_obj])\n                if verbose:\n                    print(f'Bounds: lb={lb:.2f}, ub={ub:.2f}')\n                \n                if ub - lb &lt;= eps:\n                    return OptStatus.OPTIMAL\n                \n                opt_sol = self._dsp_optimizer.opt_sol\n                self._master_optimizer.add_optimality_cut(opt_sol) \n            elif dsp_status == OptStatus.UNBOUNDED:\n                if verbose:\n                    print(f'DSP is unbounded!!!')\n                extreme_ray = self._dsp_optimizer.extreme_ray\n                self._master_optimizer.add_feasibility_cut(extreme_ray)\n            else:\n                if verbose:\n                    print(f\"DSP solve ERROR!!!\")\n                return OptStatus.ERROR\n\n\n\n\n\n\n4.2.6.2 Master and subproblem solvers based on Gurobi\nListing 4.23 implements a master problem solver class named GenericMasterSolverGurobi for (RBMP) characterized by the cost coefficient f, the constraint matrix B and right-hand side b. The constructor initializes the complicating variables _y and the dummy variable _g. The solve() function solves the problem and retrieves the optimal solution if exists. Moreover, the solver provides functions to add optimality and feasibility cuts to the existing model.\n\n\n\n\nListing 4.23: Generic Benders master problem solver for LP problems\n\n\nclass BendersMasterOptimizerGurobi(BendersMasterOptimizer):\n    \n    def __init__(self, f: np.array, B: np.array, b: np.array):\n        # save data\n        self._f = f\n        self._B = B\n        self._b = b \n        \n        # env and model\n        self._env = gp.Env('MasterEnv', empty=True)\n        self._env.setParam(\"OutputFlag\",0)\n        self._env.start()\n        self._model = gp.Model(env=self._env, name='MasterSolver')\n        \n        # create variables\n        self._num_y_vars = len(f)\n        self._y = self._model.addVars(self._num_y_vars, \n                                      lb=0,\n                                      vtype=GRB.CONTINUOUS, \n                                      name='y')\n        self._g = self._model.addVar(vtype=GRB.CONTINUOUS, \n                                     lb=0, \n                                     name='g')\n        \n        # create objective\n        self._model.setObjective(\n            gp.quicksum(self._f[i] * self._y.get(i) \n                        for i in range(self._num_y_vars)) + \n            self._g,  \n            GRB.MINIMIZE)\n        self._model.update()\n        \n        self._opt_obj = None\n        self._opt_obj_y = None\n        self._opt_y = None\n        self._opt_g = None\n        \n    def solve(self) -&gt; OptStatus:\n        print('-' * 50)\n        print(f'Start solving master problem.')\n        self._model.optimize()\n        \n        opt_status = None\n        if self._model.status == GRB.OPTIMAL:\n            opt_status = OptStatus.OPTIMAL\n            self._opt_obj = self._model.objVal\n            self._opt_y = {\n                i: self._y.get(i).X\n                for i in range(self._num_y_vars)\n            }\n            self._opt_g = self._g.X\n            self._opt_obj_y = self._opt_obj - self._opt_g\n            print(f'\\tmaster problem is optimal.')\n            print(f'\\topt_obj={self._opt_obj:.2f}')\n            print(f'\\topt_g={self._opt_g:.2f}')\n            for j in range(self._num_y_vars):\n                print(f'\\topt_y{j}={self._y.get(j).X}')\n        elif self._model.status == GRB.INFEASIBLE:\n            print(f'\\tmaster problem is infeasible.')\n            opt_status = OptStatus.INFEASIBLE\n        else:\n            print(f'\\tmaster problem encountered error.')\n            opt_status = OptStatus.ERROR\n        \n        print(f'Finish solving master problem.') \n        print('-' * 50)\n        return opt_status\n    \n    def add_feasibility_cut(self, ray_u: dict) -&gt; None:\n        constr_expr = [\n            ray_u.get(u_idx) * \n            (\n                self._b[u_idx] - \n                gp.quicksum(\n                    self._B[u_idx][j] * self._y.get(j) \n                    for j in range(self._num_y_vars)\n                )\n            )\n            for u_idx in ray_u.keys()\n        ]\n        self._model.addConstr(gp.quicksum(constr_expr) &lt;= 0)\n        print(f'Benders feasibility cut added!')\n    \n    def add_optimality_cut(self, opt_u: dict) -&gt; None:\n        constr_expr = [\n            opt_u.get(u_idx) * \n            (\n                self._b[u_idx] - \n                gp.quicksum(\n                    self._B[u_idx][j] * self._y.get(j) \n                    for j in range(self._num_y_vars)\n                )\n            )\n            for u_idx in opt_u.keys()\n        ]\n        self._model.addConstr(gp.quicksum(constr_expr) &lt;= self._g)\n        self._model.update()\n        print(f'Benders optimality cut added!')\n    \n    def clean_up(self):\n        self._model.dispose()\n        self._env.dispose()\n        \n    def save_model(self, filename):\n        self._model.write(filename)\n        \n    @property\n    def f(self):\n        return self._f\n        \n    @property\n    def opt_obj(self):\n        return self._opt_obj\n    \n    @property\n    def opt_obj_y(self):\n        return self._opt_obj_y\n    \n    @property\n    def opt_y(self):\n        return self._opt_y\n    \n    @property\n    def opt_g(self):\n        return self._g\n\n\n\n\nListing 4.24 presents a solver for (DSP) that’s defined by the objective function coefficient c and constraint matrix A. The model objective function could be updated by update_objective() with the latest value of y. Notice that, the optimal solution is saved to _opt_u if the underlying problem is optimal. Otherwise, an extreme ray is retrieved and stored in _extreme_ray.\n\n\n\n\nListing 4.24: Generic Benders dual subproblem solver for LP problems\n\n\nclass GenericSubprobSolverGurobi:\n    \n    def __init__(self, A: np.array, c: np.array, B: np.array, b: np.array):\n        # save data\n        self._A = A \n        self._c = c \n        self._b = b \n        self._B = B\n        \n        # env and model\n        self._env = gp.Env('SubprobEnv', empty=True)\n        self._env.setParam(\"OutputFlag\",0)\n        self._env.start()\n        self._model = gp.Model(env=self._env, name='SubprobSolver')\n\n        # create variables\n        self._num_vars = len(b)\n        self._u = self._model.addVars(self._num_vars, \n                                      vtype=GRB.CONTINUOUS,\n                                      lb=-GRB.INFINITY,\n                                      ub=GRB.INFINITY,\n                                      name='u')\n\n        # create constraints\n        for c_idx in range(len(c)):\n            self._model.addConstr(\n                gp.quicksum(A[:,c_idx][i] * self._u.get(i) \n                            for i in range(len(b))) &lt;= c[c_idx]\n            )\n        \n        self._opt_obj = None\n        self._opt_u = None\n        self._ray_u = None\n        \n    def solve(self):\n        print('-' * 50)\n        print(f'Start solving dual subproblem.')\n        self._model.setParam(GRB.Param.DualReductions, 0)\n        self._model.setParam(GRB.Param.InfUnbdInfo, 1)\n        self._model.optimize()\n        \n        status = None\n        if self._model.status == GRB.OPTIMAL:\n            self._opt_obj = self._model.objVal\n            self._opt_u = {\n                i: self._u.get(i).X\n                for i in range(self._num_vars)\n            }\n            status = OptStatus.OPTIMAL\n            print(f'\\tdual subproblem is optimal.')\n            print(f'\\topt_obj={self._opt_obj:.2f}')\n            for i in range(self._num_vars):\n                print(f'\\topt_u{i}={self._u.get(i).X}')\n        elif self._model.status == GRB.UNBOUNDED:\n            status = OptStatus.UNBOUNDED\n            self._ray_u = {\n                i: self._u.get(i).UnbdRay\n                for i in range(self._num_vars)\n            }\n            print(f'dual subproblem is unbounded')\n        else:\n            print(f'dual subproblem solve ERROR!')\n            status = OptStatus.ERROR\n        \n        print(f'Finish solving dual subproblem.')\n        print('-' * 50)\n        return status\n\n    def update_objective(self, opt_y: dict):\n        obj_expr = [\n            self._u.get(u_idx) * \n            (\n                self._b[u_idx] - \n                sum(self._B[u_idx][j] * opt_y.get(j) \n                    for j in range(len(opt_y))\n                )\n            )\n            for u_idx in range(self._num_vars)\n        ]\n        self._model.setObjective(gp.quicksum(obj_expr), GRB.MAXIMIZE)\n        print(f'dual subproblem objective updated!')\n    \n    def clean_up(self):\n        self._model.dispose()\n        self._env.dispose()\n        \n    def save_model(self, filename):\n        self._model.write(filename)\n        \n    @property\n    def opt_obj(self):\n        return self._opt_obj\n    \n    @property\n    def opt_u(self):\n        return self._opt_u\n    \n    @property\n    def ray_u(self):\n        return self._ray_u\n\n\n\n\nIn Listing 4.26, we utilize the freshly baked solver to tackle the serious LP problem presented in the previous sections. The output shows that the same optimal objective value of 1091.43 was obtained in the end.\n\n\n\n\nListing 4.25: Solving the LP problem using Benders decomposition\n\n\nimport numpy as np\n\nc = np.array([8, 12, 10])\nf = np.array([15, 18])\nA = np.array([[2, 3, 2], [4, 2, 3]])\nB = np.array([[4, 5], [2, 3]])\nb = np.array([300, 220])\n\nmaster_solver = GenericMasterSolverGurobi(f, B, b)\ndual_subprob_solver = GenericSubprobSolverGurobi(A, c, B, b)\n\nbenders_solver = GenericBendersDecomposition(master_solver, dual_subprob_solver)\nstatus = benders_solver.optimize()\n\n\n\n\n\nIteration: 1\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=0.00\n    opt_g=0.00\n    opt_y0=0.0\n    opt_y1=0.0\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=0.00, ub=inf\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\n    dual subproblem is optimal.\n    opt_obj=1200.00\n    opt_u0=4.0\n    opt_u1=0.0\nFinish solving dual subproblem.\n--------------------------------------------------\nDSP is optimal!\nBounds: lb=0.00, ub=1200.00\nBenders optimality cut added!\n\nIteration: 2\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=1080.00\n    opt_g=0.00\n    opt_y0=0.0\n    opt_y1=60.0\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=1080.00, ub=1200.00\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\ndual subproblem is unbounded\nFinish solving dual subproblem.\n--------------------------------------------------\nDSP is unbounded!!!\nBenders feasibility cut added!\n\nIteration: 3\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=1091.43\n    opt_g=114.29\n    opt_y0=0.0\n    opt_y1=54.285714285714285\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=1091.43, ub=1200.00\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\n    dual subproblem is optimal.\n    opt_obj=114.29\n    opt_u0=4.0\n    opt_u1=0.0\nFinish solving dual subproblem.\n--------------------------------------------------\nDSP is optimal!\nBounds: lb=1091.43, ub=1091.43\n\n\n\n\n4.2.6.3 Master and subproblem solvers based on SCIP\n\nimport pyscipopt\n\nclass GenericMasterSolverSCIP:\n    \n    def __init__(self, f: np.array, B: np.array, b: np.array):\n        # save data\n        self._f = f\n        self._B = B\n        self._b = b \n        \n        # env and model\n        self._model = pyscipopt.Model('MasterSolver')\n        \n        # create variables\n        self._num_y_vars = len(f)\n        self._y = {\n            i: self._model.addVar(lb=0, vtype='C', name=f'y{i}')\n            for i in range(self._num_y_vars)\n        }\n        self._g = self._model.addVar(lb=0,\n                                     vtype='C',\n                                     name='g')\n        \n        # create objective\n        self._model.setObjective(\n            pyscipopt.quicksum(self._f[i] * self._y.get(i) \n                        for i in range(self._num_y_vars)) + \n            self._g,  \n            'maximize')\n        \n        self._opt_obj = None\n        self._opt_obj_y = None\n        self._opt_y = None\n        self._opt_g = None\n        \n    def solve(self) -&gt; OptStatus:\n        print('-' * 50)\n        print(f'Start solving master problem.')\n        self._model.setPresolve(pyscipopt.SCIP_PARAMSETTING.OFF)\n        self._model.setHeuristics(pyscipopt.SCIP_PARAMSETTING.OFF)\n        self._model.disablePropagation()\n        self._model.optimize()\n        \n        opt_status = None\n        print(self._model.getStatus())\n        if self._model.getStatus() == 'optimal':\n            opt_status = OptStatus.OPTIMAL\n            self._opt_obj = self._model.getObjVal()\n            self._opt_y = {\n                i: self._model.getVal(self._y.get(i))\n                for i in range(self._num_y_vars)\n            }\n            self._opt_g = self._model.getVal(self._g)\n            self._opt_obj_y = self._opt_obj - self._opt_g\n            print(f'\\tmaster problem is optimal.')\n            print(f'\\topt_obj={self._opt_obj:.2f}')\n            print(f'\\topt_g={self._opt_g:.2f}')\n            for j in range(self._num_y_vars):\n                print(f'\\topt_y{j}={self._opt_y.get(j)}')\n        elif self._model.getStatus() == 'infeasible':\n            print(f'\\tmaster problem is infeasible.')\n            opt_status = OptStatus.INFEASIBLE\n        else:\n            print(f'\\tmaster problem encountered error.')\n            opt_status = OptStatus.ERROR\n        \n        print(f'Finish solving master problem.') \n        print('-' * 50)\n        return opt_status\n    \n    def add_feasibility_cut(self, ray_u: dict) -&gt; None:\n        constr_expr = [\n            ray_u.get(u_idx) * \n            (\n                self._b[u_idx] - \n                pyscipopt.quicksum(\n                    self._B[u_idx][j] * self._y.get(j) \n                    for j in range(self._num_y_vars)\n                )\n            )\n            for u_idx in ray_u.keys()\n        ]\n        self._model.addCons(pyscipopt.quicksum(constr_expr) &lt;= 0)\n        print(f'Benders feasibility cut added!')\n    \n    def add_optimality_cut(self, opt_u: dict) -&gt; None:\n        constr_expr = [\n            opt_u.get(u_idx) * \n            (\n                self._b[u_idx] - \n                pyscipopt.quicksum(\n                    self._B[u_idx][j] * self._y.get(j) \n                    for j in range(self._num_y_vars)\n                )\n            )\n            for u_idx in opt_u.keys()\n        ]\n        self._model.addCons(pyscipopt.quicksum(constr_expr) &lt;= self._g)\n        self._model.update()\n        print(f'Benders optimality cut added!')\n    \n    @property\n    def f(self):\n        return self._f\n        \n    @property\n    def opt_obj(self):\n        return self._opt_obj\n    \n    @property\n    def opt_obj_y(self):\n        return self._opt_obj_y\n    \n    @property\n    def opt_y(self):\n        return self._opt_y\n    \n    @property\n    def opt_g(self):\n        return self._g\n\n\nimport pyscipopt\n\nclass GenericSubprobSolverSCIP:\n    \n    def __init__(self, A: np.array, c: np.array, B: np.array, b: np.array):\n        # save data\n        self._A = A \n        self._c = c \n        self._b = b \n        self._B = B\n        \n        # env and model\n        self._model = pyscipopt.Model('SubprobSolver')\n\n        # create variables\n        self._num_vars = len(b)\n        self._u = {\n            i: self._model.addVar(vtype='C',\n                                  lb=-self._model.infinity(),\n                                  ub=self._model.infinity(),\n                                  name=f'u{i}')\n            for i in range(self._num_vars)\n        }\n\n        # create constraints\n        for c_idx in range(len(c)):\n            self._model.addCons(\n                pyscipopt.quicksum(A[:,c_idx][i] * self._u.get(i) \n                            for i in range(len(b))) &lt;= c[c_idx]\n            )\n        \n        self._opt_obj = None\n        self._opt_u = None\n        self._ray_u = None\n        \n    def solve(self):\n        print('-' * 50)\n        print(f'Start solving dual subproblem.')\n        self._model.setPresolve(pyscipopt.SCIP_PARAMSETTING.OFF)\n        self._model.setHeuristics(pyscipopt.SCIP_PARAMSETTING.OFF)\n        self._model.disablePropagation()\n        self._model.optimize()\n        \n        status = None\n        if self._model.getStatus() == 'optimal':\n            self._opt_obj = self._model.getObjVal()\n            self._opt_u = {\n                i: self._model.getVal(self._u.get(i))\n                for i in range(self._num_vars)\n            }\n            status = OptStatus.OPTIMAL\n            print(f'\\tdual subproblem is optimal.')\n            print(f'\\topt_obj={self._opt_obj:.2f}')\n            for i in range(self._num_vars):\n                print(f'\\topt_u{i}={self._opt_u.get(i)}')\n        elif self._model.getStatus() == 'unbounded':\n            status = OptStatus.UNBOUNDED\n            hasRay = self._model.hasPrimalRay()\n            print(f'primal ray exists!')\n            ray = self._model.getPrimalRay()\n            self._ray_u = {\n                i: ray[i]\n                for i in range(self._num_vars)\n            }\n            print(f'dual subproblem is unbounded')\n        else:\n            print(f'dual subproblem solve ERROR!')\n            status = OptStatus.ERROR\n        \n        print(f'Finish solving dual subproblem.')\n        print('-' * 50)\n        return status\n\n    def update_objective(self, opt_y: dict):\n        obj_expr = [\n            self._u.get(u_idx) * \n            (\n                self._b[u_idx] - \n                sum(self._B[u_idx][j] * opt_y.get(j) \n                    for j in range(len(opt_y))\n                )\n            )\n            for u_idx in range(self._num_vars)\n        ]\n        self._model.setObjective(pyscipopt.quicksum(obj_expr), GRB.MAXIMIZE)\n        print(f'dual subproblem objective updated!')\n    \n    @property\n    def opt_obj(self):\n        return self._opt_obj\n    \n    @property\n    def opt_u(self):\n        return self._opt_u\n    \n    @property\n    def ray_u(self):\n        return self._ray_u\n\nListing 4.26 solves same the LP problem that we have been tackling in the previous sections. The output confirms that the same optimal solution is identified as in the last section.\n\n\n\n\nListing 4.26: Solving the LP problem using Benders decomposition\n\n\nimport numpy as np\n\nc = np.array([8, 12, 10])\nf = np.array([15, 18])\nA = np.array([[2, 3, 2], [4, 2, 3]])\nB = np.array([[4, 5], [2, 3]])\nb = np.array([300, 220])\n\nmaster_solver = GenericMasterSolverSCIP(f, B, b)\ndual_subprob_solver = GenericSubprobSolverSCIP(A, c, B, b)\n\nbenders_solver = GenericBendersDecomposition(master_solver, dual_subprob_solver)\nbenders_solver.optimize()\n\n\n\n\n\nIteration: 1\n--------------------------------------------------\nStart solving master problem.\nunbounded\n    master problem encountered error.\nFinish solving master problem.\n--------------------------------------------------\npresolving:\n   (0.0s) symmetry computation started: requiring (bin +, int +, cont +), (fixed: bin -, int -, cont -)\n   (0.0s) no symmetry present (symcode time: 0.00)\npresolving (0 rounds: 0 fast, 0 medium, 0 exhaustive):\n 0 deleted vars, 0 deleted constraints, 0 added constraints, 0 tightened bounds, 0 added holes, 0 changed sides, 0 changed coefficients\n 0 implications, 0 cliques\npresolved problem has 3 variables (0 bin, 0 int, 0 impl, 3 cont) and 0 constraints\nPresolving Time: 0.00\n\n time | node  | left  |LP iter|LP it/n|mem/heur|mdpt |vars |cons |rows |cuts |sepa|confs|strbr|  dualbound   | primalbound  |  gap   | compl. \n* 0.0s|     1 |     0 |     0 |     - |    LP  |   0 |   3 |   0 |   0 |   0 |  0 |   0 |   0 |      --      |      --      |   0.00%| unknown\n  0.0s|     1 |     0 |     0 |     - |   568k |   0 |   3 |   0 |   0 |   0 |  0 |   0 |   0 |      --      |      --      |   0.00%| unknown\n\nSCIP Status        : problem is solved [unbounded]\nSolving Time (sec) : 0.00\nSolving Nodes      : 1\nPrimal Bound       : +1.00000000000000e+20 (1 solutions)\nDual Bound         : +1.00000000000000e+20\nGap                : 0.00 %\n\n\nTypeError: '&gt;=' not supported between instances of 'float' and 'NoneType'\n\n\n\n\n4.2.6.4 Detect infeasibility\n\nimport numpy as np\n\nnp.random.seed(142)\nc = np.random.randint(2, 6, size=20)\nf = np.random.randint(1, 15, size=10)\nA = np.random.randint(2, 6, size=(20, 20))\nB = np.random.randint(2, 26, size=(20, 10))\nb = np.random.randint(20, 50, size=20)\n\nobj_coeff = np.concatenate([c, f])\nconstr_mat = np.concatenate([A, B], axis=1)\nrhs = b\n\n\ngurobi_solver = LpSolverGurobi(obj_coeff, constr_mat, rhs)\ngurobi_solver.save_model('problem2.lp')\ngurobi_solver.optimize()\n\nModel is infeasible!\n\n\n\nscip_solver = LpSolverSCIP(obj_coeff, constr_mat, rhs)\nscip_solver.optimize()\n\nModel is infeasible!\n\n\n\nmaster_solver = GenericLpMasterSolver(f, B, b)\ndual_subprob_solver = GenericLpSubprobSolver(A, c, B, b)\n\nbenders_solver = GenericBendersSolver(master_solver, dual_subprob_solver)\nbenders_solver.optimize()\n\n\nIteration: 1\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=0.00\n    opt_g=0.00\n    opt_y0=0.0\n    opt_y1=0.0\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=0.00, ub=inf\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\n    dual subproblem is optimal.\n    opt_obj=1200.00\n    opt_u0=4.0\n    opt_u1=0.0\nFinish solving dual subproblem.\n--------------------------------------------------\nDSP is optimal!\nBounds: lb=0.00, ub=1200.00\nBenders optimality cut added!\n\nIteration: 2\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=1080.00\n    opt_g=0.00\n    opt_y0=0.0\n    opt_y1=60.0\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=1080.00, ub=1200.00\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\ndual subproblem is unbounded\nFinish solving dual subproblem.\n--------------------------------------------------\nDSP is unbounded!!!\nBenders feasibility cut added!\n\nIteration: 3\n--------------------------------------------------\nStart solving master problem.\n    master problem is optimal.\n    opt_obj=1091.43\n    opt_g=114.29\n    opt_y0=0.0\n    opt_y1=54.285714285714285\nFinish solving master problem.\n--------------------------------------------------\nBounds: lb=1091.43, ub=1200.00\ndual subproblem objective updated!\n--------------------------------------------------\nStart solving dual subproblem.\n    dual subproblem is optimal.\n    opt_obj=114.29\n    opt_u0=4.0\n    opt_u1=0.0\nFinish solving dual subproblem.\n--------------------------------------------------\nDSP is optimal!\nBounds: lb=1091.43, ub=1091.43\n\n\n\n\n\n4.2.7 Implementation with callbacks\n\n\n4.2.8 Testing and validation",
    "crumbs": [
      "Benders Decomposition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Benders Decomposition</span>"
    ]
  }
]